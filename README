# PDF â†’ RAG â†’ QLoRA Model

This project builds a small language model trained on your own PDF datasheets.  
The pipeline performs:

1. Extract text from PDF files  
2. Split text into chunks  
3. Create embeddings  
4. Build a FAISS search index  
5. Generate a synthetic SFT dataset  
6. Fine-tune a base model using QLoRA  
7. Run inference using RAG or without RAG

---

## ðŸš€ Features

- PDF text extraction  
- Text chunking  
- Embedding generation with MiniLM  
- FAISS vector search  
- QLoRA finetuning on Qwen2.5-1.5B  
- Simple inference script

---

## Main Files

- `pdf_texts/` â€“ extracted PDF text  
- `all_chunks.jsonl` â€“ chunked data  
- `faiss_index.idx` â€“ FAISS index  
- `faiss_meta.json` â€“ metadata  
- `sft_dataset.jsonl` â€“ synthetic training data  
- `gemma-qlora-adapter/` â€“ LoRA adapter  
- `train_qlora.py` â€“ model training  
- `inference.py` â€“ answering questions

---

##  Installation

```bash
pip install transformers peft bitsandbytes sentence-transformers faiss-cpu pdfplumber
